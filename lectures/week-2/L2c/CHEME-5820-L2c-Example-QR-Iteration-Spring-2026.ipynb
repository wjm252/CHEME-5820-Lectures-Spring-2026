{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8771d2db",
   "metadata": {},
   "source": [
    "# Example: Computing the Eigendecomposition using QR decomposition of a Covariance Matrix\n",
    "In this example, we will compute the eigendecomposition of a covariance matrix using the QR algorithm, which relies on the Gram-Schmidt process for orthogonalization. The covariance matrix will be computed from the daily log growth rate of stock prices.\n",
    "\n",
    "> __Learning Objectives__\n",
    "> \n",
    "> By the end of this example, you should be able to:\n",
    "> THree learning objectives go here\n",
    "\n",
    "Let's get started!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772fb80",
   "metadata": {},
   "source": [
    "## Setup, Data, and Prerequisites\n",
    "First, we set up the computational environment by including the `Include.jl` file and loading any needed resources.\n",
    "\n",
    "> The [`include(...)` command](https://docs.julialang.org/en/v1/base/base/#include) evaluates the contents of the input source file, `Include.jl`, in the notebook's global scope. The `Include.jl` file sets paths, loads required external packages, etc. For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). \n",
    "\n",
    "Let's set up our code environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "345c2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"Include.jl\")); # include the Include.jl file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5328f7",
   "metadata": {},
   "source": [
    "In addition to standard Julia libraries, we'll also use [the `VLDataScienceMachineLearningPackage.jl` package](https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl). Check out [the documentation](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/) for more information on the functions, types, and data used in this material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d12776",
   "metadata": {},
   "source": [
    "### Data\n",
    "We gathered a daily open-high-low-close dataset for each firm in the S&P 500 from `01-03-2014` until `12-31-2024`, along with data for a few exchange-traded funds and volatility products during that time. \n",
    "\n",
    "Let's load the `original_dataset::DataFrame` by calling [the `MyTrainingMarketDataSet()` function](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/data/#VLDataScienceMachineLearningPackage.MyTrainingMarketDataSet) and remove firms that do not have the maximum number of trading days. The cleaned dataset $\\mathcal{D}$ will be stored in the `dataset` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeaafdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = MyTrainingMarketDataSet() |> x-> x[\"dataset\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72747488",
   "metadata": {},
   "source": [
    "Not all tickers in our dataset have the maximum number of trading days for various reasons, e.g., acquisition or de-listing events. Let's collect only those tickers with the maximum number of trading days.\n",
    "\n",
    "First, let's compute the number of records for a firm that we know has a maximum value, e.g., `AAPL`, and save that value in the `maximum_number_trading_days::Int64` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36621b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_number_trading_days = original_dataset[\"AAPL\"] |> nrow;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157167e",
   "metadata": {},
   "source": [
    "Now, let's iterate through our data and collect only tickers with `maximum_number_trading_days` records. Save that data in the `dataset::Dict{String,DataFrame}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73324cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = let\n",
    "\n",
    "    dataset = Dict{String,DataFrame}();\n",
    "    for (ticker,data) ∈ original_dataset\n",
    "        if (nrow(data) == maximum_number_trading_days)\n",
    "            dataset[ticker] = data;\n",
    "        end\n",
    "    end\n",
    "    dataset\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b1fde",
   "metadata": {},
   "source": [
    "Finally, let's get a list of the firms in our cleaned dataset (and sort them alphabetically). We store the sorted firm ticker symbols in the `list_of_tickers::Array{String,1}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ffa2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424-element Vector{String}:\n",
       " \"A\"\n",
       " \"AAL\"\n",
       " \"AAP\"\n",
       " \"AAPL\"\n",
       " \"ABBV\"\n",
       " \"ABT\"\n",
       " \"ACN\"\n",
       " \"ADBE\"\n",
       " \"ADI\"\n",
       " \"ADM\"\n",
       " ⋮\n",
       " \"WYNN\"\n",
       " \"XEL\"\n",
       " \"XOM\"\n",
       " \"XRAY\"\n",
       " \"XYL\"\n",
       " \"YUM\"\n",
       " \"ZBRA\"\n",
       " \"ZION\"\n",
       " \"ZTS\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_tickers = keys(dataset) |> collect |> sort # list of firm \"ticker\" symbols in alphabetical order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75618a1f",
   "metadata": {},
   "source": [
    "Finally, let's set up a ticker map that holds the index of each ticker value. We'll save this in the `tickerindexmap::Dict{String,Int}` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ead51ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Int64} with 424 entries:\n",
       "  \"EMR\"  => 132\n",
       "  \"CTAS\" => 101\n",
       "  \"HSIC\" => 187\n",
       "  \"KIM\"  => 217\n",
       "  \"PLD\"  => 310\n",
       "  \"IEX\"  => 194\n",
       "  \"BAC\"  => 48\n",
       "  \"CBOE\" => 69\n",
       "  \"EXR\"  => 144\n",
       "  \"NCLH\" => 271\n",
       "  \"CVS\"  => 103\n",
       "  \"DRI\"  => 119\n",
       "  \"DTE\"  => 120\n",
       "  \"ZION\" => 423\n",
       "  \"AVY\"  => 43\n",
       "  \"EW\"   => 140\n",
       "  \"EA\"   => 124\n",
       "  \"NWSA\" => 289\n",
       "  \"CAG\"  => 65\n",
       "  ⋮      => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tickerindexmap = let\n",
    "\n",
    "    # initialize -\n",
    "    tickerindexmap = Dict{String,Int}();\n",
    "    for i ∈ eachindex(list_of_tickers)\n",
    "        tickerindexmap[list_of_tickers[i]] = i;\n",
    "    end\n",
    "\n",
    "    tickerindexmap;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96eb5f1",
   "metadata": {},
   "source": [
    "### Compute the growth rate matrix\n",
    "Next, let's compute the growth rate array which contains, for each day and each firm in our dataset, the value of the growth rate between time $j$ and $j-1$. \n",
    "\n",
    ">  __Continuously Compounded Growth Rate (CCGR)__\n",
    ">\n",
    "> Let's assume a model of the share price of firm $i$ is governed by an expression of the form:\n",
    ">$$\n",
    "\\begin{align*}\n",
    "S^{(i)}_{j} &= S^{(i)}_{j-1}\\;\\exp\\left(g^{(i)}_{j,j-1}\\Delta{t}_{j}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "> where $S^{(i)}_{j-1}$ denotes the share price of firm $i$ at time index $j-1$, $S^{(i)}_{j}$ denotes the share price of firm $i$ at time index $j$, and $\\Delta{t}_{j} = t_{j} - t_{j-1}$ denotes the length of a time step (units: years) between time index $j-1$ and $j$. The value we are going to estimate is the growth rate $g^{(i)}_{j,j-1}$ (units: inverse years) for each firm $i$, and each time step in the dataset.\n",
    "\n",
    "We've implemented [the `log_growth_matrix(...)` function](https://varnerlab.github.io/VLDataScienceMachineLearningPackage.jl/dev/data/#VLDataScienceMachineLearningPackage.log_growth_matrix) which takes the cleaned dataset and a list of ticker symbols, and returns the growth rate array. Each row of the growth rate array is a time step, while each column corresponds to a firm from the `list_of_tickers::Array{String,1}` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea1cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rate_array = let\n",
    "\n",
    "    # initialize -\n",
    "    τ = (1/252); # time-step one-day in units of years (trading year is 252 days)\n",
    "    r̄ = 0.0; # assume the risk-free rate is 0\n",
    "\n",
    "    # compute the growth matrix -\n",
    "    growth_rate_array = log_growth_matrix(dataset, list_of_tickers, Δt = τ, \n",
    "        risk_free_rate = r̄); # other optional parameters are at their defaults\n",
    "\n",
    "    growth_rate_array; # return\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e3fbc",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1087e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "One concise, direct summary sentence goes here\n",
    "\n",
    "> __Key Takeaways__\n",
    "> \n",
    "> Three key takeaways go here\n",
    "\n",
    "One concise, direct conclusion sentence goes here\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.4",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
